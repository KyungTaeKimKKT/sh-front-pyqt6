from __future__ import annotations
from typing import Any, Callable, Dict, List, Optional, Tuple, Union, TYPE_CHECKING

from modules.common_import_v3 import *
import cv2
import numpy as np

import mediapipe as mp

from plugin_main.menus.ai.face_register import MainImageLabel, Mixin_MediaPipe
from plugin_main.menus.ai.mixin_face import Mixin_Face
from modules.PyQt.compoent_v2.grid.container_lb_pixmap import Custom_Grid

from plugin_main.menus.ai.dlg_face_result import RecognitionResultDialog



if TYPE_CHECKING:
    from main_test  import WSClient

class ImagesLabel(QLabel):
    def __init__(self, parent=None, image:np.ndarray=None):
        super().__init__(parent)
        self.setFixedSize(100, 100)
        self.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.setStyleSheet("QLabel { background-color: #000000; }")
        if image is not None:
            self.set_image(image)
    
    def set_image(self, image:np.ndarray):
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        qimg = QImage(rgb_image.data, rgb_image.shape[1], rgb_image.shape[0], rgb_image.shape[2]*rgb_image.shape[1], QImage.Format.Format_RGB888)
        qimg = qimg.scaled(self.width(), self.height())
        self.setPixmap(QPixmap.fromImage(qimg))
        

class Dlg_Status_Verify(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.hide()
        self.setWindowTitle("ì–¼êµ´ ì¸ì‹ ìƒíƒœ")
        # self.setWindowFlags(Qt.WindowType.Dialog | Qt.WindowType.CustomizeWindowHint)
        self.setFixedSize(600, 600)
        self.setup_ui()

        
    def setup_ui(self):     
        self.main_layout = QVBoxLayout(self)
        self.tb_status = QTextBrowser(self)
        self.tb_status.setAcceptRichText(True)
        self.tb_status.setOpenExternalLinks(True)
        self.tb_status.setText("Status: Ready")
        self.main_layout.addWidget(self.tb_status)
        self.images_layout = QHBoxLayout()
        self.images_layout.setContentsMargins(0, 0, 0, 0)
        self.images_layout.setSpacing(0)
        self.main_layout.addLayout(self.images_layout)
        self.setLayout(self.main_layout)

    def set_status(self, status:str):
        self.tb_status.setText(status)

    def add_status(self, status:str):
        current_text = self.tb_status.toPlainText()
        self.tb_status.setText(f"{current_text}\n{status}")

    def set_images(self, images:list[np.ndarray]):
        Utils.clearLayout(self.images_layout)
        for i, img in enumerate(images):
            label = ImagesLabel()
            label.set_image(img)
            self.images_layout.addWidget(label)


class FaceRecognizeDialog_with_grpc(QDialog, Mixin_MediaPipe, Mixin_Face):
    """
    - ì—´ë¦¬ìë§ˆì Mediapipeë¡œ ìë™ ê°ì§€/í‘œì‹œ
    - ë²„íŠ¼ 1ê°œ: 'ì¸ì‹ ìš”ì²­'
      > ì§§ê²Œ Nì¥ ìƒ˜í”Œ ìˆ˜ì§‘(ì¤‘ë³µ ë°©ì§€: ì‹œê°„/ì›€ì§ì„ ê²Œì´íŠ¸)
      > ì„œë²„ /verify/ í˜¸ì¶œ (í•„ë“œëª…ì€ í”„ë¡œì íŠ¸ì— ë§ì¶° ì¡°ì •)
    - lb_statusì— ê²°ê³¼ í‘œì‹œ
    """
    def __init__(self, parent=None, verify_url:str="ai-face/user-face/recognize_via_rpc/", user_id:int=None, api_client=None,  is_hidden:bool=True,**kwargs):
        super().__init__(parent)
        self.kwargs = kwargs
        self.is_hidden = is_hidden
        self.is_hidden_dlg_status_verify = kwargs.get('is_hidden_dlg_status_verify', True)
        if self.is_hidden:
            self.hide()

        self.start_time = time.perf_counter()
        self.verify_url = verify_url  # ì„œë²„ ì—”ë“œí¬ì¸íŠ¸ ë§ì¶° ìˆ˜ì •
        self.user_id = user_id                                      # í•„ìš” ì‹œ None í—ˆìš©
        self.api = api_client                                       # APP.API ê°™ì€ ë˜í¼ ì£¼ì…

        # ìƒíƒœ
        self.frame: np.ndarray = None
        self.probe_images: list[np.ndarray] = []
        self.last_bbox = None
        self.last_capture_time = 0.0

        # Mediapipe (ê·¼ê±°ë¦¬ ì›¹ìº ì´ë©´ model_selection=0 ê¶Œì¥)
        self.mp_face = mp.solutions.face_detection
        self.face_detector = self.mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6)

        self.workers:list[Worker_by_signal] = []

        self.setup_ui()
        self.connect_signals()

        self.mixin_init_camera()

    def set_images(self, images:list[np.ndarray]):
        return 
        if not hasattr(self, 'grid_layout') : return

        widgets = [ ImagesLabel(image=image) for image in images ]
        self.grid_layout.set_widgets(widgets)

    def connect_signals(self):
        self.btn_verify.clicked.connect(self.on_click_verify)

    def disconnect_signals(self):
        try:
            self.btn_verify.clicked.disconnect(self.on_click_verify)
        except Exception as e:
            logger.error(f"disconnect_signals : {e}")

    def setup_ui(self):
        # UI
        self.setWindowTitle("Face Verify")
        self.image_label = MainImageLabel()
        self.lb_status = QLabel("Status: Ready")
        self.btn_verify = QPushButton("ì¸ì‹ ìš”ì²­")  # í•œ ê°œë§Œ

        layout = QVBoxLayout()
        layout.addWidget(self.image_label)
        layout.addWidget(self.lb_status)
        layout.addWidget(self.btn_verify)

        self.sub_container = QWidget()
        self.grid_layout = Custom_Grid(self.sub_container)

        layout.addWidget(self.sub_container)

        self.setLayout(layout)



    # -------------------- ìˆ˜ì§‘ ë¡œì§ --------------------
    def should_keep(self, bbox, min_interval=0.1, min_movement=6) -> bool:
        """
        ì¤‘ë³µ ë°©ì§€:
        - min_interval: ìµœê·¼ ìº¡ì²˜ ì‹œê°ê³¼ ìµœì†Œ ê°„ê²©(ì´ˆ)
        - min_movement: ì´ì „ bbox ì¤‘ì‹¬ê³¼ì˜ ìµœì†Œ ì´ë™ í”½ì…€
        """
        now = time.time()
        if (now - self.last_capture_time) < min_interval:
            return False

        if self.last_bbox is not None:
            (x1, y1, x2, y2) = bbox
            cx, cy = (x1 + x2)//2, (y1 + y2)//2
            (lx1, ly1, lx2, ly2) = self.last_bbox
            lcx, lcy = (lx1 + lx2)//2, (ly1 + ly2)//2
            dist = np.hypot(cx - lcx, cy - lcy)
            if dist < min_movement:
                return False

        return True

    def try_collect_probe(self, frame: np.ndarray, det, target_size=(160,160)) -> bool:
        """
        ê°ì§€ëœ ì–¼êµ´ì—ì„œ 160x160 crop ì¶”ì¶œí•´ probe_imagesì— ì¶”ê°€.
        - ì„±ê³µ ì‹œ True.
        """
        x1, y1, x2, y2 = self.get_det_bbox(frame, det)

        if not self.should_keep((x1, y1, x2, y2)):
            return False

        crop = frame[y1:y2, x1:x2]
        if crop.size == 0:
            return False

        crop = np.ascontiguousarray(cv2.resize(crop, target_size))
        self.probe_images.append(crop)
        self.last_capture_time = time.time()
        self.last_bbox = (x1, y1, x2, y2)
        return True

    # -------------------- í”„ë ˆì„ ì—…ë°ì´íŠ¸ --------------------
    def update_frame(self):
        if self.cap is None:
            return
        ok, frame = self.cap.read()
        if not ok:
            return

        self.frame = frame.copy()
        display_frame = frame.copy()
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_detector.process(rgb)

        if results.detections:
            # í‘œì‹œìš© ì˜¤ë²„ë ˆì´
            display_frame, cropped_face = self.render_frame_by_mediapipe( frame, display_frame, results)
            # ìˆ˜ì§‘ì€ ìë™ìœ¼ë¡œ ê³„ì† í•˜ì§€ëŠ” ì•Šê³ , 'ì¸ì‹ ìš”ì²­' ì‹œì— í•œ ë²ˆì— ëª¨ìŒ
        self.image_label.set_image(display_frame)

    # -------------------- ë²„íŠ¼: ì¸ì‹ ìš”ì²­ --------------------
    def on_click_verify(self):
        """
            1) ì ê¹ ë™ì•ˆ(Nì¥ ëª¨ì„ ë•Œê¹Œì§€ or timeout) ìë™ ìˆ˜ì§‘
            2) ì„œë²„ì— ì—…ë¡œë“œ â†’ ê²°ê³¼ í‘œì‹œ
        """
        if APP.get_DLG_LOADING() is not None:
            APP.get_DLG_LOADING().start_display(start_time=1000)
        self.lb_status.setText("Status: ìˆ˜ì§‘ ì¤‘...")
        # self.collect_burst_async(n=5, timeout=3.0)  # í•„ìš” ì‹œ ì¡°ì • (ê°œìˆ˜/ì‹œê°„)

        ########## ìˆ˜ì§‘ ì¤‘ ##########
        worker = Worker_by_signal(self.collect_burst, n=5, timeout=3.0)
        worker.signal.finished.connect(self.on_hanlde_collect)
        worker.start()
        self.workers.append(worker)


    def get_send_data_and_files(self) -> tuple[dict, list]:
        files = []
        for i, img in enumerate(self.probe_images):
            files.append(("images", self.ndarray_to_file(img, f"probe_{i}.jpg")))
        data = {}
        if self.user_id is not None:
            data["user_id"] = self.user_id            
        data['ws_url'] = getattr(self, 'ws_url', '')
        return data, files

    def send_verify(self):
        # APP.get_DLG_LOADING().start_display(start_time=1000)
        try:
            data, files = self.get_send_data_and_files()
            worker = Worker_by_signal(APP.API.Send, url=self.verify_url, dataObj={'id': -1}, sendData=data, sendFiles=files)
            worker.signal.finished.connect(self.on_hanlde_verify)
            worker.start()
            self.workers.append(worker)

        except Exception as e:
            self.lb_status.setText(f"Status: ì˜ˆì™¸ - {e}")
        finally:
            # ë‹¤ìŒ ìš”ì²­ ëŒ€ë¹„ ì´ˆê¸°í™”
            self.probe_images.clear()
            self.last_bbox = None
            self.last_capture_time = 0.0

    def on_hanlde_collect(self, worker:Worker_by_signal, is_ok:bool, response:any):
        self.workers.remove(worker)
        if is_ok:
            self.start_time = time.perf_counter()
            QTimer.singleShot(0, lambda: self.show_probe_images_and_send_verify(response))
            # self.send_verify()
        else:
            self.lb_status.setText(f"Status: ìˆ˜ì§‘ ì‹¤íŒ¨ (ì–¼êµ´ ë¶€ì¡±)")

    def show_probe_images_and_send_verify(self, images):
        self.probe_images = images
        if INFO.IS_DEV:
            os.makedirs("./debug", exist_ok=True)
            for i, img in enumerate(images):
                cv2.imwrite(f"./debug/probe_image_{i}.jpg", img)
            # cv2.waitKey(0)
        self.lb_status.setText(f"Status: {len(images)} ìˆ˜ì§‘ ì™„ë£Œ")
        self.send_verify()

    def on_hanlde_verify(self, worker:Worker_by_signal, is_ok:bool, response:any):
        print (f"on_hanlde_verify: {worker} {is_ok} {len(response)} ")
        _isok, _json = response ##: tuple[bool, any]
        if APP.get_DLG_LOADING() is not None:
            APP.get_DLG_LOADING().stop_display()
        if _isok:
            self.lb_status.setText(f"Status: {Utils.get_json_pretty(_json, delete_keys=['decision_images'])}")
            dlg_face_result = RecognitionResultDialog(self, result_data=_json)
            if dlg_face_result.exec():
                pass
            else:
                pass

        else:
            self.lb_status.setText(f"Status: ì‹¤íŒ¨ - {_json}")

        self.workers.remove(worker)


    def collect_burst(self, n=5, timeout=3.0) -> list[np.ndarray]:
        self.probe_images.clear()
        self.last_bbox = None
        self.last_capture_time = 0.0

        t0 = time.time()
        while len(self.probe_images) < n and (time.time() - t0) < timeout:
            ret, frame = self.cap.read()
            if not ret:
                continue
            self.frame = frame.copy()
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.face_detector.process(rgb)
            if results.detections:
                self.try_collect_probe(frame, results.detections[0])
            # cv2.waitKey(1)  # ë„ˆë¬´ ë¹ ë¥¸ ë£¨í”„ ë°©ì§€
        return self.probe_images

    def collect_burst_async(self, n=5, timeout=3.0):
        self.probe_images.clear()
        self.last_bbox = None
        self.last_capture_time = 0.0

        t0 = time.time()
        def try_capture():
            if len(self.probe_images) >= n or (time.time() - t0) > timeout:
                self.timer_capture.stop()
                return
            if self.frame is not None:
                rgb = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)
                results = self.face_detector.process(rgb)
                if results.detections:
                    self.try_collect_probe(self.frame, results.detections[0])
        
        self.timer_capture = QTimer()
        self.timer_capture.timeout.connect(try_capture)
        self.timer_capture.start(30)  # 30msë§ˆë‹¤ ì‹œë„

    # -------------------- ì¢…ë£Œ --------------------
    def closeEvent(self, e):
        print (f"closeEvent: {self}")
        try:
            if getattr(self, 'timer_capture', None):
                self.timer_capture.stop()
                self.timer_capture = None
            if getattr(self, 'timer', None):
                self.timer.stop()
                self.timer = None

            if hasattr(self, 'cap') and self.cap is not None:
                if self.cap.isOpened():
                    self.cap.release()
                self.cap = None

            # ğŸ”‘ ì¥ì¹˜ ìºì‹œ í´ë¦¬ì–´ (íŠ¹íˆ ë¦¬ëˆ…ìŠ¤)
            if getattr(self, 'cam_index', None):
                cv2.VideoCapture(self.cam_index).release()

            if getattr(self, 'ws_manager', None) and hasattr(self.ws_manager, 'remove'):
                self.ws_manager.remove(self.ws_url)

        finally:
            super().closeEvent(e)

    def done(self, r):
        """
        exec() â†’ accept()/reject() ë¡œ ëë‚  ë•ŒëŠ” closeEvent() ìë™ í˜¸ì¶œì´ ì•ˆ ë  ìˆ˜ ìˆìŒ

        ë”°ë¼ì„œ done() ì˜¤ë²„ë¼ì´ë“œí•˜ê±°ë‚˜, finished ì‹œê·¸ë„ì—ì„œ close() ë¥¼ ê°•ì œë¡œ í˜¸ì¶œí•˜ëŠ” ê²Œ ë§ìŒ
        exec() ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ QDialog.accept() / QDialog.reject() ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.

        ì´ ê²½ìš° ì‹¤ì œ closeEvent() ê°€ íŠ¸ë¦¬ê±°ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ (íŠ¹íˆ Qt6ë¶€í„°).

        ì¦‰, close() ë¡œ ë‹«ì„ ë•Œë§Œ closeEvent() ê°€ ë³´ì¥ í˜¸ì¶œë¼ìš”
        """
        print("done() called", r)
        self.close()   # ì—¬ê¸°ì„œ ê°•ì œ close() í˜¸ì¶œ
        super().done(r)


class FaceRecognizeDialog(QDialog, Mixin_MediaPipe, Mixin_Face):
    """
    - ì—´ë¦¬ìë§ˆì Mediapipeë¡œ ìë™ ê°ì§€/í‘œì‹œ
    - ë²„íŠ¼ 1ê°œ: 'ì¸ì‹ ìš”ì²­'
      > ì§§ê²Œ Nì¥ ìƒ˜í”Œ ìˆ˜ì§‘(ì¤‘ë³µ ë°©ì§€: ì‹œê°„/ì›€ì§ì„ ê²Œì´íŠ¸)
      > ì„œë²„ /verify/ í˜¸ì¶œ (í•„ë“œëª…ì€ í”„ë¡œì íŠ¸ì— ë§ì¶° ì¡°ì •)
    - lb_statusì— ê²°ê³¼ í‘œì‹œ
    """
    def __init__(self, parent=None, verify_url:str=None, user_id:int=None, api_client=None,  is_hidden:bool=True,**kwargs):
        super().__init__(parent)
        self.kwargs = kwargs
        self.is_hidden = is_hidden
        self.is_hidden_dlg_status_verify = kwargs.get('is_hidden_dlg_status_verify', True)
        if self.is_hidden:
            self.hide()

        self.start_time = time.perf_counter()
        self.verify_url = verify_url or "ai-face/user-face/recognize/"  # ì„œë²„ ì—”ë“œí¬ì¸íŠ¸ ë§ì¶° ìˆ˜ì •
        self.user_id = user_id                                      # í•„ìš” ì‹œ None í—ˆìš©
        self.api = api_client                                       # APP.API ê°™ì€ ë˜í¼ ì£¼ì…

        # ìƒíƒœ
        self.frame: np.ndarray = None
        self.probe_images: list[np.ndarray] = []
        self.last_bbox = None
        self.last_capture_time = 0.0

        # Mediapipe (ê·¼ê±°ë¦¬ ì›¹ìº ì´ë©´ model_selection=0 ê¶Œì¥)
        self.mp_face = mp.solutions.face_detection
        self.face_detector = self.mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.6)

        self.workers:list[Worker_by_signal] = []

        self.setup_ui()
        self.connect_signals()
        self.create_dlg_status_verify()

        self.mixin_init_camera()
        self.mixin_init_ws( ws_manager = kwargs.get('ws_manager', None),
                      ws_url_base = kwargs.get('ws_url_base', "broadcast/") 
                      )

    def create_dlg_status_verify(self):
        self.dlg_status_verify = Dlg_Status_Verify(self)




    def set_images(self, images:list[np.ndarray]):
        return 
        if not hasattr(self, 'grid_layout') : return

        widgets = [ ImagesLabel(image=image) for image in images ]
        self.grid_layout.set_widgets(widgets)

    def connect_signals(self):
        self.btn_verify.clicked.connect(self.on_click_verify)

    def disconnect_signals(self):
        try:
            self.btn_verify.clicked.disconnect(self.on_click_verify)
        except Exception as e:
            logger.error(f"disconnect_signals : {e}")

    def setup_ui(self):
        # UI
        self.setWindowTitle("Face Verify")
        self.image_label = MainImageLabel()
        self.lb_status = QLabel("Status: Ready")
        self.btn_verify = QPushButton("ì¸ì‹ ìš”ì²­")  # í•œ ê°œë§Œ

        layout = QVBoxLayout()
        layout.addWidget(self.image_label)
        layout.addWidget(self.lb_status)
        layout.addWidget(self.btn_verify)

        self.sub_container = QWidget()
        self.grid_layout = Custom_Grid(self.sub_container)

        layout.addWidget(self.sub_container)

        self.setLayout(layout)



    # -------------------- ìˆ˜ì§‘ ë¡œì§ --------------------
    def should_keep(self, bbox, min_interval=0.1, min_movement=6) -> bool:
        """
        ì¤‘ë³µ ë°©ì§€:
        - min_interval: ìµœê·¼ ìº¡ì²˜ ì‹œê°ê³¼ ìµœì†Œ ê°„ê²©(ì´ˆ)
        - min_movement: ì´ì „ bbox ì¤‘ì‹¬ê³¼ì˜ ìµœì†Œ ì´ë™ í”½ì…€
        """
        now = time.time()
        if (now - self.last_capture_time) < min_interval:
            return False

        if self.last_bbox is not None:
            (x1, y1, x2, y2) = bbox
            cx, cy = (x1 + x2)//2, (y1 + y2)//2
            (lx1, ly1, lx2, ly2) = self.last_bbox
            lcx, lcy = (lx1 + lx2)//2, (ly1 + ly2)//2
            dist = np.hypot(cx - lcx, cy - lcy)
            if dist < min_movement:
                return False

        return True

    def try_collect_probe(self, frame: np.ndarray, det, target_size=(160,160)) -> bool:
        """
        ê°ì§€ëœ ì–¼êµ´ì—ì„œ 160x160 crop ì¶”ì¶œí•´ probe_imagesì— ì¶”ê°€.
        - ì„±ê³µ ì‹œ True.
        """
        x1, y1, x2, y2 = self.get_det_bbox(frame, det)

        if not self.should_keep((x1, y1, x2, y2)):
            return False

        crop = frame[y1:y2, x1:x2]
        if crop.size == 0:
            return False

        crop = np.ascontiguousarray(cv2.resize(crop, target_size))
        self.probe_images.append(crop)
        self.last_capture_time = time.time()
        self.last_bbox = (x1, y1, x2, y2)
        return True

    # -------------------- í”„ë ˆì„ ì—…ë°ì´íŠ¸ --------------------
    def update_frame(self):
        if self.cap is None:
            return
        ok, frame = self.cap.read()
        if not ok:
            return

        self.frame = frame.copy()
        display_frame = frame.copy()
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_detector.process(rgb)

        if results.detections:
            # í‘œì‹œìš© ì˜¤ë²„ë ˆì´
            display_frame, cropped_face = self.render_frame_by_mediapipe( frame, display_frame, results)
            # ìˆ˜ì§‘ì€ ìë™ìœ¼ë¡œ ê³„ì† í•˜ì§€ëŠ” ì•Šê³ , 'ì¸ì‹ ìš”ì²­' ì‹œì— í•œ ë²ˆì— ëª¨ìŒ
        self.image_label.set_image(display_frame)

    # -------------------- ë²„íŠ¼: ì¸ì‹ ìš”ì²­ --------------------
    def on_click_verify(self):
        """
        1) ì ê¹ ë™ì•ˆ(Nì¥ ëª¨ì„ ë•Œê¹Œì§€ or timeout) ìë™ ìˆ˜ì§‘
        2) ì„œë²„ì— ì—…ë¡œë“œ â†’ ê²°ê³¼ í‘œì‹œ
        """
        APP.get_DLG_LOADING().start_display(start_time=1000)
        self.lb_status.setText("Status: ìˆ˜ì§‘ ì¤‘...")
        # self.collect_burst_async(n=5, timeout=3.0)  # í•„ìš” ì‹œ ì¡°ì • (ê°œìˆ˜/ì‹œê°„)

        ########## ìˆ˜ì§‘ ì¤‘ ##########
        worker = Worker_by_signal(self.collect_burst, n=5, timeout=3.0)
        worker.signal.finished.connect(self.on_hanlde_collect)
        worker.start()
        self.workers.append(worker)


    def get_send_data_and_files(self) -> tuple[dict, list]:
        files = []
        for i, img in enumerate(self.probe_images):
            files.append(("images", self.ndarray_to_file(img, f"probe_{i}.jpg")))
        data = {}
        if self.user_id is not None:
            data["user_id"] = self.user_id            
        data['ws_url'] = self.ws_url
        return data, files

    def send_verify(self):
        try:
            data, files = self.get_send_data_and_files()
            worker = Worker_by_signal(APP.API.Send, url=self.verify_url, dataObj={'id': -1}, sendData=data, sendFiles=files)
            worker.signal.finished.connect(self.on_hanlde_verify)
            worker.start()
            self.workers.append(worker)
        except Exception as e:
            self.lb_status.setText(f"Status: ì˜ˆì™¸ - {e}")
        finally:
            # ë‹¤ìŒ ìš”ì²­ ëŒ€ë¹„ ì´ˆê¸°í™”
            self.probe_images.clear()
            self.last_bbox = None
            self.last_capture_time = 0.0

    def on_hanlde_collect(self, worker:Worker_by_signal, is_ok:bool, response:any):
        self.workers.remove(worker)
        if is_ok:
            self.start_time = time.perf_counter()
            QTimer.singleShot(0, lambda: self.show_probe_images_and_send_verify(response))
            # self.send_verify()
        else:
            self.lb_status.setText(f"Status: ìˆ˜ì§‘ ì‹¤íŒ¨ (ì–¼êµ´ ë¶€ì¡±)")

    def show_probe_images_and_send_verify(self, images):
        self.probe_images = images
        if INFO.IS_DEV:
            os.makedirs("./debug", exist_ok=True)
            for i, img in enumerate(images):
                cv2.imwrite(f"./debug/probe_image_{i}.jpg", img)
            self.dlg_status_verify.set_images(images)
            # cv2.waitKey(0)
        self.lb_status.setText(f"Status: {len(images)} ìˆ˜ì§‘ ì™„ë£Œ")
        self.send_verify()

    def on_hanlde_verify(self, worker:Worker_by_signal, is_ok:bool, response:any):
        print (f"on_hanlde_verify: {worker} {is_ok} {len(response)} ")
        _isok, _json = response ##: tuple[bool, any]
        if _isok:
            self.lb_status.setText(f"Status: {_json}")
            self.dlg_status_verify.add_status( f" result: {_json}")
            self.dlg_status_verify.add_status( f" request time: {Utils.get_ì†Œìš”ì‹œê°„(self.start_time) }")
        else:
            self.lb_status.setText(f"Status: ì‹¤íŒ¨ - {_json}")

        if len(self.workers) == 0:
            self.dlg_status_verify.close()
        self.workers.remove(worker)
        APP.get_DLG_LOADING().stop_display()

    def on_ws_message(self, url: str, data: dict):
        """ mixin_faceì—ì„œ í˜¸ì¶œí•¨ """
        print (f"on_ws_message: {url} {data}")

        dlg_face_result = RecognitionResultDialog(self, result_data=data)
        if dlg_face_result.exec():
            pass
        else:
            pass
        # self.dlg_status_verify.add_status( json.dumps(data, indent=4) )
        # self.dlg_status_verify.add_status( f" ì´ verify ì†Œìš”ì‹œê°„: {Utils.get_ì†Œìš”ì‹œê°„(self.start_time) }")
        

    def collect_burst(self, n=5, timeout=3.0) -> list[np.ndarray]:
        self.probe_images.clear()
        self.last_bbox = None
        self.last_capture_time = 0.0

        t0 = time.time()
        while len(self.probe_images) < n and (time.time() - t0) < timeout:
            ret, frame = self.cap.read()
            if not ret:
                continue
            self.frame = frame.copy()
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.face_detector.process(rgb)
            if results.detections:
                self.try_collect_probe(frame, results.detections[0])
            # cv2.waitKey(1)  # ë„ˆë¬´ ë¹ ë¥¸ ë£¨í”„ ë°©ì§€
        return self.probe_images

    def collect_burst_async(self, n=5, timeout=3.0):
        self.probe_images.clear()
        self.last_bbox = None
        self.last_capture_time = 0.0

        t0 = time.time()
        def try_capture():
            if len(self.probe_images) >= n or (time.time() - t0) > timeout:
                self.timer_capture.stop()
                return
            if self.frame is not None:
                rgb = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)
                results = self.face_detector.process(rgb)
                if results.detections:
                    self.try_collect_probe(self.frame, results.detections[0])
        
        self.timer_capture = QTimer()
        self.timer_capture.timeout.connect(try_capture)
        self.timer_capture.start(30)  # 30msë§ˆë‹¤ ì‹œë„

    # -------------------- ì¢…ë£Œ --------------------
    def closeEvent(self, e):
        print (f"closeEvent: {self}")
        try:
            if getattr(self, 'timer_capture', None):
                self.timer_capture.stop()
                self.timer_capture = None
            if getattr(self, 'timer', None):
                self.timer.stop()
                self.timer = None

            if hasattr(self, 'cap') and self.cap is not None:
                if self.cap.isOpened():
                    self.cap.release()
                self.cap = None

            # ğŸ”‘ ì¥ì¹˜ ìºì‹œ í´ë¦¬ì–´ (íŠ¹íˆ ë¦¬ëˆ…ìŠ¤)
            if getattr(self, 'cam_index', None):
                cv2.VideoCapture(self.cam_index).release()

            if getattr(self, 'ws_manager', None) and hasattr(self.ws_manager, 'remove'):
                self.ws_manager.remove(self.ws_url)

        finally:
            super().closeEvent(e)

    def done(self, r):
        """
        exec() â†’ accept()/reject() ë¡œ ëë‚  ë•ŒëŠ” closeEvent() ìë™ í˜¸ì¶œì´ ì•ˆ ë  ìˆ˜ ìˆìŒ

        ë”°ë¼ì„œ done() ì˜¤ë²„ë¼ì´ë“œí•˜ê±°ë‚˜, finished ì‹œê·¸ë„ì—ì„œ close() ë¥¼ ê°•ì œë¡œ í˜¸ì¶œí•˜ëŠ” ê²Œ ë§ìŒ
        exec() ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ QDialog.accept() / QDialog.reject() ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.

        ì´ ê²½ìš° ì‹¤ì œ closeEvent() ê°€ íŠ¸ë¦¬ê±°ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ (íŠ¹íˆ Qt6ë¶€í„°).

        ì¦‰, close() ë¡œ ë‹«ì„ ë•Œë§Œ closeEvent() ê°€ ë³´ì¥ í˜¸ì¶œë¼ìš”
        """
        print("done() called", r)
        self.close()   # ì—¬ê¸°ì„œ ê°•ì œ close() í˜¸ì¶œ
        super().done(r)